I didn't write a codebook for these data but the question text can be found in the _text version of the data. 

The deflecting events in this version of the survey are balanced in that they have the same number of Actor-, Behavior-, and Object- deflecting events. 
I followed Nelson's design in using a fixed list of events for each condition. However, a future design might improve on this  by presenting respondents with randomly selected events, evenly balanced. 

The first part of this survey follows Nelson's design: a 'teaching' task as Part 1, followed by the deflecting events in Part 2. 
I added a "Part 3": I asked participants afterward to look at the events once more and to simply say, for each event they had just seen, wether they thought that event was strange or not. Basically, a simple direct test to see whether people perceived deflection *at all* with a Likert measure of *how much*. 
